{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | max samSize: [3.57, 4.76] mm\n",
      " | gamma_gpd  > gamma_min: 1.66 > 9\n",
      " | gamma_diff > gamma_min: 1.33 > 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import torch\n",
    "\n",
    "# Define centered FFT routines\n",
    "def fft2c(x):\n",
    "    return fftshift(fft2(ifftshift(x), axes=(0,1)))\n",
    "\n",
    "def fft2c_cuda(x):\n",
    "    return torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(x), dim=(0,1)))\n",
    "\n",
    "def ifft2c(x):\n",
    "    return fftshift(ifft2(ifftshift(x), axes=(0,1)))\n",
    "\n",
    "def ifft2c_cuda(x):\n",
    "    return torch.fft.fftshift(torch.fft.ifft2(torch.fft.ifftshift(x), dim=(0,1)))\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "\n",
    "# Laser\n",
    "wl = 0.532  # Wavelength in micrometers\n",
    "\n",
    "# GPD (Diffuser)\n",
    "gpd_dir = os.path.join('microretarders_mfile.mat')  # File containing diffuser data\n",
    "input_pol = 'R'    # Polarization: 'R' (or 'L')\n",
    "gpd_flip = 1       # Flip diffuser horizontally if needed\n",
    "gpd_pix = 30       # Diffuser pixel size in micrometers\n",
    "gpd_size = (512, 512)  # Dimensions of diffuser grid\n",
    "\n",
    "# Camera\n",
    "cam_flip = 0                  # Camera flip flag\n",
    "cam_pix = 3.1                 # Camera pixel size in micrometers\n",
    "cam_crop_size = (1024, 1024)     # Cropped sensor size\n",
    "\n",
    "# Lenses\n",
    "f1 = 300000     # Focal length of lens 1 in micrometers\n",
    "f2 = 200000     # Focal length of lens 2 in micrometers\n",
    "mag = f2 / f1   # System magnification\n",
    "gamma_min = 9   # Minimum gamma threshold\n",
    "\n",
    "# Display\n",
    "display_pix = 36  # Display pixel size in micrometers\n",
    "M_disp = display_pix / cam_pix * f2 / f1  # Display magnification factor\n",
    "display_size = (768, 1024)\n",
    "# Ensure display size does not exceed camera crop size:\n",
    "display_size = (min(display_size[0], cam_crop_size[0]), min(display_size[1], cam_crop_size[1]))\n",
    "effRectSize = (display_size[0] * display_pix / M_disp, display_size[1] * display_pix / M_disp)  # Effective sample FOV in um\n",
    "\n",
    "# Gamma Checks\n",
    "diffFOV = (gpd_size[0] * gpd_pix, gpd_size[1] * gpd_pix)  # Diffuser FOV in micrometers\n",
    "N_max = np.prod(np.array(effRectSize) * np.array(diffFOV) / (wl * f1))  # Max resolvable elements\n",
    "M_gpd = np.prod(gpd_size)  # Total diffuser pixels\n",
    "M_camera = np.prod(np.array(cam_crop_size) * cam_pix * np.array(diffFOV) / (wl * f2))  # Camera resolution elements\n",
    "\n",
    "gamma_gpd = M_gpd / N_max\n",
    "gamma_diff = M_camera / N_max\n",
    "\n",
    "print(f\" | max samSize: [{effRectSize[0]*1e-3:.2f}, {effRectSize[1]*1e-3:.2f}] mm\")\n",
    "print(f\" | gamma_gpd  > gamma_min: {gamma_gpd:.2f} > {gamma_min}\")\n",
    "print(f\" | gamma_diff > gamma_min: {gamma_diff:.2f} > {gamma_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Diffuser Field ---\n",
    "anglescan = -0.19867  # Rotation angle for the diffuser (deg)\n",
    "magscan = 0.9985      # Magnification correction factor\n",
    "\"\"\"\n",
    "diffuser_E, _, GPDwindow = utils.gpdField(\n",
    "    gpd_dir, gpd_size, gpd_pix, gpd_flip, input_pol,\n",
    "    cam_crop_size, cam_pix, cam_flip, wl, f1, f2, effRectSize,\n",
    "    gpdRot=-anglescan, gpdMag=1/magscan\n",
    ")\n",
    "\"\"\"\n",
    "diffuser_E = sio.loadmat('diffuser_E.mat')\n",
    "diffuser_E = diffuser_E['diffuserE']\n",
    "cam_pix2 = (cam_pix, cam_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sample Parameters & Optimization Settings ---\n",
    "is_sample_circle = 1    # 1: Circular aperture, 0: Square aperture\n",
    "sam_FOV = 1.2e3     # Sample FOV in micrometers\n",
    "\n",
    "optimization_method = 'FISTA'\n",
    "correlation_critical = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sample Mask (samMask)\n",
    "padSize = diffuser_E.shape\n",
    "if is_sample_circle:\n",
    "    # Calculate radii in pixel units:\n",
    "    rr = (round(sam_FOV * mag / cam_pix2[0] / 2), round(sam_FOV * mag / cam_pix2[1] / 2))\n",
    "    # Create circular mask (note: mk_ellipse returns True outside the ellipse)\n",
    "    sample_mask = ~utils.mk_ellipse(rr[1], rr[0], padSize[1], padSize[0])\n",
    "else:\n",
    "    sample_mask_size = (round(sam_FOV * mag / cam_pix2[0]), round(sam_FOV * mag / cam_pix2[1]))\n",
    "    sample_mask = np.ones(sample_mask_size, dtype=bool)\n",
    "    sample_mask = utils.mpad(sample_mask, padSize)\n",
    "    \n",
    "# Crop the sample mask to the display size for SLM mapping.\n",
    "sample_mask_SLM = utils.mcrop(sample_mask, display_size)\n",
    "# Compute row/column indices with nonzero mask sums.\n",
    "mask1 = np.where(np.sum(sample_mask_SLM, axis=1) > 0)[0]\n",
    "mask2 = np.where(np.sum(sample_mask_SLM, axis=0) > 0)[0]\n",
    "\n",
    "# (In this translation we stick with numpy arrays. For GPU acceleration, consider using cupy.)\n",
    "sample_mask_SLM = sample_mask_SLM.copy()\n",
    "sample_mask = sample_mask.copy()\n",
    "\n",
    "# temporary\n",
    "pad_size = (1024, 1024)\n",
    "spk_window = utils.mpad(np.ones(cam_crop_size, dtype=bool), pad_size)\n",
    "\n",
    "# Bring diffuser field to \"GPU\" memory and apply ifftshift.\n",
    "X_iter_0 = 'random'  # Initial guess type for reconstruction\n",
    "\n",
    "# --- Ramp Calculation for SLM Pattern ---\n",
    "Y_grid, X_grid = utils.ndgrid_matSizeIn(display_size, 0, 'centerZero')\n",
    "ramp = 2 * np.pi * ((X_grid * 0.5) + (Y_grid * 0.5))\n",
    "ramp = ramp.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SLM Calibration ---\n",
    "phaseVal, SLMDigit = utils.SLM_LUT()\n",
    "\n",
    "def phase2digit(x):\n",
    "    # Convert phase values to SLM digit values using nearest interpolation.\n",
    "    return np.interp(x, phaseVal, SLMDigit)\n",
    "\n",
    "shiftvec = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 1/1 [00:13<00:00, 13.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# from main_loop import main_loop\n",
    "from main_loop import main_loop\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def load_mat_file(file_path):\n",
    "    data = {}\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            # Convert HDF5 datasets to numpy arrays.\n",
    "            data[key] = np.array(f[key])\n",
    "    return data\n",
    "\n",
    "path = \"rawImages-004.mat\"\n",
    "data = load_mat_file(path)\n",
    "imgbuffer = data.get('imgbuffer')\n",
    "imgbuffer = imgbuffer.transpose(1,2,0)\n",
    "\n",
    "# Generate pupil-plane field image.\n",
    "fields_pupil = np.zeros_like(imgbuffer, dtype=np.uint8)\n",
    "fields = np.zeros_like(imgbuffer, dtype=np.uint8)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "for i in tqdm(range(350, 370, batch_size), desc='processing...'):\n",
    "    psi = imgbuffer[:,:,i:i+batch_size].astype(np.float32)\n",
    "    psi = np.transpose(psi, axes=(1, 0, 2))\n",
    "    psi = np.real(np.sqrt(psi))\n",
    "    \n",
    "    X_final = main_loop(psi, diffuser_E, sample_mask, spk_window, shiftvec)\n",
    "    \n",
    "    gpd_window = sio.loadmat('GPD_window.mat')\n",
    "    gpd_window = gpd_window['GPDwindow']\n",
    "    gpd_window = np.stack([gpd_window] * X_final.shape[2], axis=2)\n",
    "    \n",
    "    X_final = fft2c(np.roll(X_final, shift=(shiftvec[0], shiftvec[1]), axis=(0, 1))) * gpd_window\n",
    "    # X_final = fft2c(X_final) * gpd_window\n",
    "    X_final = ifft2c(X_final)\n",
    "\n",
    "    absX = np.abs(X_final)\n",
    "    perc = np.percentile(absX, 99.9)\n",
    "    fields_pupil[:, :, i:i+batch_size] = (256 * absX / perc).astype(np.uint8)\n",
    "\n",
    "    # Process again for the final output field image.\n",
    "    X_final = ifft2c(X_final)\n",
    "    absX = np.abs(X_final)\n",
    "    perc = np.percentile(absX, 99.9)\n",
    "    fields[:, :, i:i+batch_size] = (256 * absX / perc).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing...: 100%|██████████| 105/105 [16:08<00:00,  9.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from main_loop_speed import main_loop\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "def load_mat_file(file_path):\n",
    "    data = {}\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            # Convert HDF5 datasets to numpy arrays.\n",
    "            data[key] = np.array(f[key])\n",
    "    return data\n",
    "\n",
    "path = \"rawImages-004.mat\"\n",
    "data = load_mat_file(path)\n",
    "imgbuffer = data.get('imgbuffer')\n",
    "imgbuffer = imgbuffer.transpose(1, 2, 0)\n",
    "\n",
    "# Generate pupil-plane field image.\n",
    "fields_pupil = np.zeros_like(imgbuffer, dtype=np.uint8)\n",
    "fields = np.zeros_like(imgbuffer, dtype=np.uint8)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "total_main_loop_time = 0\n",
    "total_other_time = 0\n",
    "\n",
    "for i in tqdm(range(0, imgbuffer.shape[2], batch_size), desc='processing...'):\n",
    "    # start_other = time.time()\n",
    "    psi = imgbuffer[:, :, i:i+batch_size].astype(np.float32)\n",
    "    psi = np.transpose(psi, axes=(1, 0, 2))\n",
    "    psi = np.real(np.sqrt(psi))\n",
    "\n",
    "    # start_main = time.time()\n",
    "    X_final = main_loop(psi, diffuser_E, sample_mask, spk_window, shiftvec)\n",
    "    # end_main = time.time()\n",
    "\n",
    "    # total_main_loop_time += (end_main - start_main)\n",
    "\n",
    "    gpd_window = sio.loadmat('GPD_window.mat')\n",
    "    gpd_window = gpd_window['GPDwindow']\n",
    "    gpd_window = np.stack([gpd_window] * X_final.shape[2], axis=2)\n",
    "    \n",
    "    gpd_window_torch = torch.tensor(gpd_window).cuda()\n",
    "\n",
    "    X_final = fft2c_cuda(torch.roll(X_final, shifts=(shiftvec[0], shiftvec[1]), dims=(0, 1))) * gpd_window_torch\n",
    "    X_final = ifft2c_cuda(X_final)\n",
    "    \n",
    "    # Process again for the final output field image.\n",
    "    X_final = ifft2c_cuda(X_final)\n",
    "    X_final = X_final.cpu().numpy()\n",
    "    \n",
    "    absX = np.abs(X_final)\n",
    "    perc = np.percentile(absX, 99.9)\n",
    "    fields[:, :, i:i+batch_size] = (256 * absX / perc).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    absX = np.abs(X_final)\n",
    "    perc = np.percentile(absX, 99.9)\n",
    "    fields_pupil[:, :, i:i+batch_size] = (256 * absX / perc).astype(np.uint8)\n",
    "\n",
    "    # end_other = time.time()\n",
    "    # total_other_time += (end_other - start_other) - (end_main - start_main)\n",
    "\n",
    "# print(f\"Total time spent in main_loop: {total_main_loop_time:.2f} seconds\")\n",
    "# print(f\"Total time spent in other operations: {total_other_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Save to HDF5\n",
    "with h5py.File('fields.h5', 'w') as f:\n",
    "    f.create_dataset('fields', data=fields)\n",
    "    f.create_dataset('fields_pupil', data=fields_pupil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'fields' at 0x2dff9c16ae0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\envs\\tele\\Lib\\site-packages\\napari\\_vispy\\layers\\scalar_field.py:198: UserWarning: data shape (1024, 1024, 2100) exceeds GL_MAX_TEXTURE_SIZE 2048 in at least one axis and will be downsampled. Rendering is currently in 3D mode.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tele",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
